# Elastic Pipeline Extension

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]  |
| Distributions | [] |
| Issues        | TBD |
| Code coverage | TBD |
| [Code Owners](https://github.com/elastic/opentelemetry-collector-components/blob/main/CONTRIBUTING.md#becoming-a-code-owner)    | TBD |

[development]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md#development
<!-- end autogenerated section -->

This extension enables dynamic loading and management of OpenTelemetry Collector pipeline configurations stored in Elasticsearch. It fetches pipeline definitions from a central `.otel-pipeline-config` index and applies them to the running collector without requiring a restart.

## Architecture Overview

The `elasticpipelineextension` combines concepts from:
- **apmconfigextension**: Remote configuration fetching from Elasticsearch with caching
- **fileintegrationextension**: Dynamic pipeline integration capabilities
- **Collector Configuration Management**: Runtime pipeline creation and management

### Core Components

1. **Elasticsearch Pipeline Fetcher**: Retrieves pipeline configurations from `.otel-pipeline-config` index
2. **Pipeline Manager**: Handles dynamic creation, update, and removal of pipelines
3. **Configuration Watcher**: Monitors for configuration changes and applies updates
4. **Health Monitor**: Tracks pipeline health and reports status back to Elasticsearch

## Configuration

### Basic Configuration

```yaml
extensions:
  bearertokenauth:
    scheme: "APIKey"
    token: "<YOUR_ENCODED_ELASTICSEARCH_APIKEY>"

  elasticpipeline:
    source:
      elasticsearch:
        endpoint: "<YOUR_ELASTICSEARCH_ENDPOINT>"
        auth:
          authenticator: bearertokenauth
        index: ".otel-pipeline-config"  # Default index name
    watcher:
      poll_interval: 30s              # How often to check for config changes
      cache_duration: 5m              # Cache duration for fetched configs
    pipeline_management:
      namespace: "elastic"             # Namespace for generated pipeline IDs
      enable_health_reporting: true    # Report pipeline health to Elasticsearch
      health_report_interval: 60s     # How often to report health status

service:
  extensions: [bearertokenauth, elasticpipeline]
```

### Advanced Configuration

```yaml
extensions:
  elasticpipeline:
    source:
      elasticsearch:
        endpoint: "https://elastic.example.com:9200"
        auth:
          authenticator: bearertokenauth
        index: ".otel-pipeline-config"
        # Additional ES client settings
        timeout: 30s
        max_retries: 3
    
    watcher:
      poll_interval: 30s
      cache_duration: 5m
      # Query filters for selective pipeline fetching
      filters:
        - field: "agent.environment"
          value: "production"
        - field: "agent.cluster"
          value: "us-west-1"
    
    pipeline_management:
      namespace: "elastic"
      enable_health_reporting: true
      health_report_interval: 60s
      
      # Pipeline lifecycle settings
      startup_timeout: 60s
      shutdown_timeout: 30s
      
      # Resource limits for dynamic pipelines
      max_pipelines: 50
      max_components_per_pipeline: 20
      
      # Validation settings
      validate_configs: true
      dry_run_mode: false  # Set to true for validation without applying
```

### Streaming Integration Mode

When integrated with raw sampling pipelines, the extension operates in **streaming mode** where dynamic pipelines are injected into the stream processing flow rather than operating as standalone pipelines.

```yaml
extensions:
  elasticpipeline:
    source:
      elasticsearch:
        endpoint: "http://localhost:9200"
        auth:
          authenticator: basicauth/es
        index: ".otel-pipeline-config"
    watcher:
      poll_interval: 30s
      cache_duration: 5m
    pipeline_management:
      namespace: "elastic"
      enable_health_reporting: true
      health_report_interval: 60s
      max_pipelines: 50
      max_components_per_pipeline: 20
      validate_configs: true
      dry_run_mode: false
    integration:
      mode: "streaming"                        # Enable streaming integration
      stream_ingress: "routing/stream_ingress" # Connector to receive from
      stream_egress: "routing/stream_egress"   # Connector to export to
      component_prefix: "stream_"              # Prefix for internal components
      validate_connectors: true                # Validate connectors exist
```

#### How Streaming Mode Works

In streaming mode, the extension automatically transforms pipeline configurations:

1. **Entry Pipeline Transformation**: Replaces receivers with `stream_ingress` connector
2. **Exit Pipeline Transformation**: Replaces exporters with `stream_egress` connector
3. **Component Prefixing**: Prefixes all internal connector names to avoid conflicts
4. **Filtering**: Removes receivers/exporters that conflict with static configuration

**Example Transformation**:

Original pipeline document (from `.otel-pipeline-config`):
```json
{
  "config": {
    "processors": {
      "transform/logs_metadata": { /* ... */ }
    },
    "connectors": {
      "routing/logs": { /* ... */ }
    },
    "service": {
      "pipelines": {
        "logs/application": {
          "receivers": ["otlp"],
          "processors": ["transform/logs_metadata"],
          "exporters": ["routing/logs"]
        },
        "logs/output": {
          "receivers": ["routing/logs"],
          "exporters": ["elasticsearch"]
        }
      }
    }
  }
}
```

Transformed configuration (applied to collector):
```json
{
  "processors": {
    "transform/logs_metadata": { /* ... */ }
  },
  "connectors": {
    "stream_routing/logs": { /* ... */ }
  },
  "service": {
    "pipelines": {
      "logs/application": {
        "receivers": ["routing/stream_ingress"],
        "processors": ["transform/logs_metadata"],
        "exporters": ["stream_routing/logs"]
      },
      "logs/output": {
        "receivers": ["stream_routing/logs"],
        "exporters": ["routing/stream_egress"]
      }
    }
  }
}
```

#### Static Configuration Requirements

For streaming mode, your static collector configuration must define the ingress and egress connectors:

```yaml
connectors:
  routing/stream_ingress:
    default_pipelines: [logs/sampling_decision]
    table:
      - statement: route()
        pipelines: []  # Dynamic pipelines will be added here
  
  routing/stream_egress:
    default_pipelines: []
    table:
      - statement: route()
        pipelines: [logs/sampling_decision]
```

#### Use Cases for Streaming Mode

- **Raw Sampling Integration**: Insert stream processing between raw capture and sampling decision
- **Multi-Stage Processing**: Add custom transforms without replacing entire pipelines
- **Stream-Based Routing**: Dynamic routing based on stream hierarchies
- **Gradual Migration**: Incrementally move processing logic to dynamic configurations

#### Comparison: Standalone vs Streaming

| Aspect | Standalone Mode | Streaming Mode |
|--------|----------------|----------------|
| **Pipeline Structure** | Complete, self-contained | Integrated into larger flow |
| **Receivers** | Defined in dynamic config | Replaced with stream_ingress |
| **Exporters** | Defined in dynamic config | Replaced with stream_egress |
| **Connectors** | Internal use only | Prefixed to avoid conflicts |
| **Use Case** | Independent pipelines | Stream processing integration |

## Elasticsearch Index Structure

### `.otel-pipeline-config` Index Mapping

The extension expects documents in the following structure:

```json
{
  "mappings": {
    "properties": {
      "pipeline_id": {
        "type": "keyword"
      },
      "agent": {
        "properties": {
          "environment": {"type": "keyword"},
          "cluster": {"type": "keyword"},
          "version": {"type": "keyword"},
          "labels": {
            "type": "object",
            "dynamic": true
          }
        }
      },
      "config": {
        "properties": {
          "receivers": {"type": "object", "enabled": false},
          "processors": {"type": "object", "enabled": false},
          "exporters": {"type": "object", "enabled": false},
          "connectors": {"type": "object", "enabled": false},
          "pipelines": {"type": "object", "enabled": false}
        }
      },
      "metadata": {
        "properties": {
          "created_at": {"type": "date"},
          "updated_at": {"type": "date"},
          "created_by": {"type": "keyword"},
          "version": {"type": "long"},
          "enabled": {"type": "boolean"},
          "priority": {"type": "integer"}
        }
      },
      "health": {
        "properties": {
          "status": {"type": "keyword"},
          "last_applied": {"type": "date"},
          "last_error": {"type": "text"},
          "error_count": {"type": "long"}
        }
      }
    }
  }
}
```

### Example Pipeline Configuration Document

```json
{
  "pipeline_id": "nginx-logs-prod",
  "agent": {
    "environment": "production",
    "cluster": "us-west-1",
    "labels": {
      "team": "infrastructure",
      "service": "nginx"
    }
  },
  "config": {
    "receivers": {
      "filelog/nginx": {
        "include": ["/var/log/nginx/*.log"],
        "start_at": "end",
        "operators": [
          {
            "type": "regex_parser",
            "regex": "^(?P<remote_addr>[\\d\\.]+) - (?P<remote_user>\\S+) \\[(?P<time_local>[^\\]]+)\\] \"(?P<method>\\S+) (?P<path>\\S+) (?P<protocol>\\S+)\" (?P<status>\\d+) (?P<body_bytes_sent>\\d+)"
          }
        ]
      }
    },
    "processors": {
      "transform/nginx": {
        "log_statements": [
          "set(attributes[\"service.name\"], \"nginx\")",
          "set(attributes[\"deployment.environment\"], \"production\")"
        ]
      },
      "batch/nginx": {
        "send_batch_size": 1000,
        "timeout": "10s"
      }
    },
    "exporters": {
      "elasticsearch/logs": {
        "endpoints": ["https://logs.elastic.example.com:9200"],
        "logs_index": "logs-nginx-production"
      }
    },
    "pipelines": {
      "logs/nginx": {
        "receivers": ["filelog/nginx"],
        "processors": ["transform/nginx", "batch/nginx"],
        "exporters": ["elasticsearch/logs"]
      }
    }
  },
  "metadata": {
    "created_at": "2025-10-29T12:00:00Z",
    "updated_at": "2025-10-29T12:00:00Z",
    "created_by": "admin",
    "version": 1,
    "enabled": true,
    "priority": 100
  }
}
```

## Implementation Plan

### Phase 1: Core Infrastructure

1. **Extension Framework**
   - Create extension factory and configuration structures
   - Implement basic Elasticsearch client integration
   - Set up configuration validation

2. **Elasticsearch Integration**
   - Document fetcher with query filtering
   - Index watcher with polling mechanism
   - Configuration caching with TTL support

3. **Basic Pipeline Management**
   - Pipeline configuration parser
   - Component ID namespace management
   - Basic pipeline lifecycle (create/update/delete)

### Phase 2: Dynamic Configuration Management

1. **Runtime Pipeline Operations**
   - Integration with collector's configuration reloading
   - Safe pipeline shutdown and startup procedures
   - Configuration validation before application

2. **Change Detection**
   - Document version tracking
   - Incremental configuration updates
   - Conflict resolution strategies

3. **Error Handling**
   - Graceful degradation on configuration errors
   - Rollback mechanisms for failed updates
   - Error reporting to Elasticsearch

### Phase 3: Advanced Features

1. **Health Monitoring**
   - Pipeline health status tracking
   - Metrics collection and reporting
   - Integration with collector's health check system

2. **Security and Validation**
   - Configuration schema validation
   - Security policy enforcement
   - Audit logging for configuration changes

3. **Performance Optimization**
   - Efficient configuration diffing
   - Batch configuration updates
   - Resource usage monitoring

### Phase 4: Enterprise Features

1. **Multi-tenancy Support**
   - Agent targeting by labels/environment
   - Configuration inheritance and overrides
   - Role-based access control integration

2. **Configuration Templates**
   - Template-based configuration generation
   - Variable substitution support
   - Configuration composition patterns

3. **Monitoring and Observability**
   - Configuration change metrics
   - Pipeline performance tracking
   - Integration with Elastic APM for monitoring

## Key Implementation Components

### File Structure
```
extension/elasticpipelineextension/
├── README.md
├── doc.go
├── factory.go
├── config.go
├── extension.go
├── metadata.yaml
├── internal/
│   ├── elasticsearch/
│   │   ├── client.go           # ES client wrapper
│   │   ├── fetcher.go          # Configuration fetcher
│   │   └── watcher.go          # Change monitoring
│   ├── pipeline/
│   │   ├── manager.go          # Pipeline lifecycle management
│   │   ├── validator.go        # Configuration validation
│   │   └── health.go           # Health monitoring
│   └── config/
│       ├── parser.go           # Configuration parsing
│       └── transformer.go      # Config transformation
├── testdata/
└── tests/
```

### Core Interfaces

```go
// PipelineConfigFetcher retrieves pipeline configurations from Elasticsearch
type PipelineConfigFetcher interface {
    FetchConfigurations(ctx context.Context, filters map[string]string) ([]PipelineConfig, error)
    WatchConfigurations(ctx context.Context, callback ConfigChangeCallback) error
}

// PipelineManager handles dynamic pipeline operations
type PipelineManager interface {
    ApplyConfiguration(ctx context.Context, config PipelineConfig) error
    RemoveConfiguration(ctx context.Context, pipelineID string) error
    ListManagedPipelines() []string
    GetPipelineHealth(pipelineID string) (*PipelineHealth, error)
}

// HealthReporter sends pipeline health status back to Elasticsearch
type HealthReporter interface {
    ReportHealth(ctx context.Context, pipelineID string, health PipelineHealth) error
}
```

## Security Considerations

1. **Authentication & Authorization**
   - Secure Elasticsearch access using API keys or certificates
   - Validate configuration sources and integrity
   - Implement role-based pipeline management

2. **Configuration Validation**
   - Schema validation for pipeline configurations
   - Security policy enforcement (allowed components, resource limits)
   - Configuration sanitization and injection prevention

3. **Audit & Compliance**
   - Log all configuration changes with timestamps and sources
   - Track pipeline creation, modification, and removal
   - Integration with security monitoring systems

## Monitoring and Observability

### Metrics
- `elasticpipeline_configurations_fetched_total`
- `elasticpipeline_configurations_applied_total`
- `elasticpipeline_configurations_failed_total`
- `elasticpipeline_active_pipelines`
- `elasticpipeline_fetch_duration_seconds`
- `elasticpipeline_apply_duration_seconds`

### Logs
- Configuration fetch operations
- Pipeline lifecycle events
- Error conditions and recoveries
- Health status changes

## Usage Examples

### Basic Usage
```yaml
# Collector configuration
extensions:
  elasticpipeline:
    source:
      elasticsearch:
        endpoint: "https://elasticsearch:9200"
        index: ".otel-pipeline-config"

service:
  extensions: [elasticpipeline]
```

### Advanced Filtering
```yaml
extensions:
  elasticpipeline:
    source:
      elasticsearch:
        endpoint: "https://elasticsearch:9200"
        index: ".otel-pipeline-config"
    watcher:
      filters:
        - field: "agent.environment"
          value: "${env:ENVIRONMENT}"
        - field: "agent.cluster"
          value: "${env:CLUSTER_NAME}"
```

## Migration and Compatibility

### From Static Configuration
1. Export existing pipeline configurations to Elasticsearch documents
2. Gradually migrate pipelines to dynamic management
3. Maintain backward compatibility with static configurations

### Version Management
- Support configuration versioning and rollback
- Handle schema evolution and migration
- Maintain compatibility across collector versions

## Future Enhancements

1. **Integration with Elastic Fleet**
   - Fleet policy integration for pipeline management
   - Agent enrollment and configuration distribution
   - Centralized agent monitoring and control

2. **GitOps Integration**
   - Git repository synchronization
   - Configuration as code workflows
   - CI/CD pipeline integration

3. **Machine Learning Integration**
   - Automatic pipeline optimization suggestions
   - Anomaly detection for configuration changes
   - Performance-based configuration tuning

This comprehensive plan provides a foundation for implementing a robust, enterprise-grade dynamic pipeline configuration system that integrates seamlessly with Elastic's ecosystem while maintaining the flexibility and power of OpenTelemetry's component architecture.